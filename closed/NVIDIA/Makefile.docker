# Copyright (c) 2025, NVIDIA CORPORATION.  All rights reserved.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#	 http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

ifndef MAKEFILE_DOCKER_INCLUDED
MAKEFILE_DOCKER_INCLUDED := 1

# This Makefile includes all the variables and targets used to set up NVIDIA's MLPerf Inference docker environment
include $(CURDIR)/Makefile.const
include $(CURDIR)/Makefile.build

# Used in release process, Do not modify
PARTNER_DROP = 1
PARTNER_RELEASE := 3

# Intranet returns zero, public network returns non zero
# Force the EXTERNAL_USER to be 1 if the error code is other than 1
EXTERNAL_USER ?= $(shell bash $(PROJECT_ROOT)/scripts/check_intranet.sh)
ifeq ($(EXTERNAL_USER),0)
    EXTERNAL_USER := 0
else
    EXTERNAL_USER := 1
endif

# Conditional Docker flags
ifndef DOCKER_DETACH
    DOCKER_DETACH := 0
endif
ifndef DOCKER_TAG
    DOCKER_TAG := $(UNAME)-$(ARCH)
endif

DOCKER_BUILDKIT = 1
HOST_VOL ?= ${PWD}
CONTAINER_VOL ?= /work
NO_DOCKER_PULL ?= 0
INSTALL_RGAT_DEPS ?= 0


# The below paths are for internal use only.
# If any extra mounting path is needed, please use DOCKER_ARGS environment variables
ifneq ($(wildcard /home/scratch.mlperf_inference),)
    DOCKER_MOUNTS += -v /home/scratch.mlperf_inference:/home/scratch.mlperf_inference
endif
ifneq ($(wildcard /home/mlperf_inf_dlrmv2),)
    DOCKER_MOUNTS += -v /home/mlperf_inf_dlrmv2:/home/mlperf_inf_dlrmv2
endif
ifneq ($(wildcard /home/mlperf_inf_rgat),)
    DOCKER_MOUNTS += -v /home/mlperf_inf_rgat:/home/mlperf_inf_rgat
endif
ifneq ($(wildcard /home/scratch.svc_compute_arch),)
    DOCKER_MOUNTS += -v /home/scratch.svc_compute_arch:/home/scratch.svc_compute_arch
endif
ifneq ($(wildcard /home/scratch.computelab/sudo),)
    DOCKER_MOUNTS += -v /home/scratch.computelab/sudo:/home/scratch.computelab/sudo
endif
ifneq ($(wildcard /home/scratch.dlsim),)
    DOCKER_MOUNTS += -v /home/scratch.dlsim:/home/scratch.dlsim
endif
ifneq ($(wildcard /raid/data),)
    DOCKER_MOUNTS += -v /raid/data:/raid/data
endif
ifneq ($(wildcard $(PROJECT_ROOT)/../../regression),)
    DOCKER_MOUNTS += -v $(shell realpath $(PROJECT_ROOT)/../../regression):/regression
endif
ifdef MLPERF_SCRATCH_PATH
    ifneq ($(wildcard $(MLPERF_SCRATCH_PATH)),)
        DOCKER_MOUNTS += -v $(MLPERF_SCRATCH_PATH):$(MLPERF_SCRATCH_PATH)
    else
        $(error Path set in MLPERF_SCRATCH_PATH does not exist!)
    endif
endif
ifdef VSCODE_SERVER_PATH
    DOCKER_MOUNTS += -v $(VSCODE_SERVER_PATH):/home/$(UNAME)/.vscode-server
endif

# Handle all docker environment variables
DOCKER_ENV_VAR += -e NVIDIA_VISIBLE_DEVICES=${NVIDIA_VISIBLE_DEVICES}
DOCKER_ENV_VAR += -e HISTFILE=/mnt/${HOME}/.mlperf_bash_history
# Forwarding ssh socket for git inside docker
DOCKER_ENV_VAR += -e SSH_AUTH_SOCK=/run/host-services/ssh-auth.sock
DOCKER_ENV_VAR += -e MLPERF_SCRATCH_PATH=$(MLPERF_SCRATCH_PATH)
DOCKER_ENV_VAR += -e HOST_HOSTNAME=$(HOSTNAME)
ifdef CCACHE_DIR
    DOCKER_MOUNTS += -v $(CCACHE_DIR):/home/$(UNAME)/.ccache
    DOCKER_ENV_VAR += -e CCACHE_DIR=/home/$(UNAME)/.ccache
endif

# Handle different nvidia-docker version. Do not use nvidia-docker when running with CPUs
ifneq ($(wildcard /usr/bin/nvidia-docker),)
    DOCKER_RUN_CMD := nvidia-docker run
    # Set Environment variables to fix docker client and server version mismatch
    # Related issue: https://github.com/kubernetes-sigs/kubespray/issues/6160
    export DOCKER_API_VERSION=1.40
else
    DOCKER_RUN_CMD := docker run --runtime=nvidia
endif

# If specific DOCKER_COMMAND is not passed, launch interactive docker container session.
ifeq ($(DOCKER_COMMAND),)
    DOCKER_INTERACTIVE_FLAGS = -it
else
    DOCKER_INTERACTIVE_FLAGS =
endif


# Docker container host name
RANDOM := $(shell bash -c 'echo $$RANDOM')
DOCKER_NAME := mlperf-inference-$(DOCKER_TAG)-$(RANDOM)

############################## DOCKER TAG / NAME ##############################
# Dockerfile
DOCKER_FILENAME := docker/Dockerfile

SSH_AGENT_CMD = eval $$(ssh-agent -s) && ssh-add /home/${USER}/.ssh/* 2>/dev/null || true &&

extra_docker_flags := --ssh default

BASE_IMAGE_NAME ?= mlpinf-$(VERSION)-cuda$(CUDA_VER)-${BASE_IMAGE_ALIAS}-ubuntu$(UBUNTU_VERSION)-$(BUILD_CONTEXT)
ifeq ($(PARTNER_DROP), 1)
    BASE_IMAGE_NAME = mlpinf-$(VERSION).$(PARTNER_RELEASE)-cuda$(CUDA_VER)-${BASE_IMAGE_ALIAS}-ubuntu$(UBUNTU_VERSION)-$(BUILD_CONTEXT)-partner
    CONTAINER_REGISTRY := nvcr.io/yrleydyexu3y/mlpinf-partner-$(subst .,,$(VERSION))/mlpinf-partner-$(subst .,,$(VERSION))
else ifeq ($(SUBMITTER), NVIDIA)
    CONTAINER_REGISTRY := gitlab-master.nvidia.com/mlpinf/mlperf-inference
else ifeq ($(SUBMITTER), COMMUNITY)
    CONTAINER_REGISTRY := nvcr.io/nvidia/mlperf/mlperf-inference
endif



PREBUILD_ENV_VARS := \
    BASE_IMAGE=$(CONTAINER_REGISTRY):$(BASE_IMAGE_NAME) \
    ENV=$(ENV) \
    BUILD_CONTEXT=$(BUILD_CONTEXT) \
    CUDA_VER=$(CUDA_VER) \
    TRT_VER=$(TRT_VER) \
    MITTEN_HASH=$(MITTEN_PUBLIC_HASH) \
    MITTEN_GIT_URL=$(MITTEN_PUBLIC_GIT_URL) \
    INSTALL_RGAT_DEPS=$(INSTALL_RGAT_DEPS)
ifeq ($(ENV), release)
    PREBUILD_ENV_VARS += \
        LOADGEN_HASH=$(LOADGEN_HASH) \
        INFERENCE_URL=$(INFERENCE_URL) \
        TRTLLM_HASH=$(TRTLLM_HASH) \
        TRTLLM_URL=$(TRTLLM_URL)
endif




DOCKER_BUILD_ARGS := $(foreach var,$(PREBUILD_ENV_VARS),--build-arg $(var)) $(extra_docker_flags)

# Check if the user is currently under NVIDIA intranet. External users should see 1.
.PHONY: check_intranet
check_intranet:
	@echo "EXTERNAL_USER = $(EXTERNAL_USER)"

# Small helper to check if nvidia-docker is installed correctly.
.PHONY: docker_sanity
docker_sanity:
	docker pull nvcr.io/nvidia/cuda:11.0.3-runtime-ubuntu18.04
	$(DOCKER_RUN_CMD) --rm \
		-e NVIDIA_VISIBLE_DEVICES=${NVIDIA_VISIBLE_DEVICES} \
		nvcr.io/nvidia/cuda:11.0.3-runtime-ubuntu18.04 nvidia-smi
	@echo "Nvidia-docker is installed correctly!"


# Build the docker image and launch an interactive container.
# For CPU builds, first build the backend libraries and copy them into the working directory
.PHONY: prebuild
prebuild: check_user_requirements
ifeq ($(BUILD_TRITON), 1)
	@$(MAKE) -f Makefile.build build_triton_backends
endif
	@$(MAKE) -f Makefile.docker build_docker
ifneq ($(strip ${DOCKER_DETACH}), 1)
	@$(MAKE) -f Makefile.docker attach_docker || true
endif

# UID 0 is reserved for the root user, which is not allowed to run the docker container.
.PHONY: check_user_requirements
check_user_requirements:
	@if [ $(UID) -eq 0 ]; then \
		echo "ERROR: User $(UNAME) has UID 0 (root). This is not allowed for security reasons."; \
		exit 1; \
	fi
	@if [ "$(NO_GPU_DETECTED)" -eq 1 ]; then  \
		echo "No NVIDIA GPU detected."; exit 1; \
	fi

.PHONY: build_docker
build_docker:
	@echo "Building Docker image"
ifeq ($(PARTNER_DROP), 1)
	@echo "PARTNER_DROP: $(VERSION).$(PARTNER_RELEASE)"
endif
	@echo "BASE_IMAGE: $(BASE_IMAGE_NAME)"
	@echo "DOCKER_FILENAME: $(DOCKER_FILENAME)"
ifeq ($(NO_DOCKER_PULL), 0)
	docker pull $(CONTAINER_REGISTRY):$(BASE_IMAGE_NAME)
endif
	$(SSH_AGENT_CMD) docker buildx build --target $(ENV) -t mlperf-inference:$(DOCKER_TAG)-$(ENV)-latest $(DOCKER_BUILD_ARGS) \
		--network host --build-context common=docker/common \
		-f $(DOCKER_FILENAME) docker


# Add current user into docker image.
.PHONY: docker_add_user
docker_add_user:
	@echo "Adding user account into image"
	DOCKER_BUILDKIT=$(DOCKER_BUILDKIT) docker build -t mlperf-inference:$(DOCKER_TAG)-$(ENV)-latest --network host \
		--build-arg BASE_IMAGE=mlperf-inference:$(DOCKER_TAG)-$(ENV)-latest \
		--build-arg GID=$(GROUPID) --build-arg UID=$(UID) --build-arg GROUP=$(GROUPNAME) --build-arg USER=$(UNAME) \
		- < docker/Dockerfile.user

# Add user and launch an interactive container session.
.PHONY: attach_docker
attach_docker:
	@$(MAKE) -f Makefile.docker docker_add_user
	@$(MAKE) -f Makefile.docker launch_docker

# Launch a container session.
.PHONY: launch_docker
launch_docker:
	eval $$(ssh-agent -s) > /dev/null 2>&1 && \
	$(DOCKER_RUN_CMD) --rm $(DOCKER_INTERACTIVE_FLAGS) -w /work \
		-v $(realpath $(HOST_VOL)):$(CONTAINER_VOL) -v $(realpath ${HOME}):/mnt/${HOME} \
		--cap-add SYS_ADMIN --cap-add SYS_TIME \
		--shm-size=32gb \
		--ulimit memlock=-1 \
		-v $$SSH_AUTH_SOCK:/run/host-services/ssh-auth.sock \
		-v /etc/timezone:/etc/timezone:ro -v /etc/localtime:/etc/localtime:ro \
		-v /var/run/docker.sock:/var/run/docker.sock \
		--security-opt apparmor=unconfined --security-opt seccomp=unconfined \
		--name $(DOCKER_NAME) -h $(subst _,-,$(shell echo $(DOCKER_NAME) | cut -c -64)) --add-host $(subst _,-,$(DOCKER_NAME)):127.0.0.1 \
		--cpuset-cpus $(shell taskset -c -p $$$$ | awk '{print $$NF}') \
		--user $(UID) --net host --device /dev/fuse \
		$(DOCKER_MOUNTS) $(DOCKER_ARGS) \
		$(DOCKER_ENV_VAR) \
		$(shell if [ -n "$$MIG_CONF" ] && [ "$$MIG_CONF" = "ALL" ]; then echo "--gpus all -e NVIDIA_MIG_CONFIG_DEVICES=all"; elif [ -n "$$MIG_CONF" ] && [ "$$MIG_CONF" != "OFF" ]; then echo "--gpus '\"device=`bash scripts/mig_get_uuid.sh`\"'"; fi) \
		mlperf-inference:$(DOCKER_TAG)-$(ENV)-latest $(DOCKER_COMMAND)

endif # ifndef MAKEFILE_DOCKER_INCLUDED

